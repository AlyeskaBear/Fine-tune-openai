{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f9567d",
   "metadata": {},
   "source": [
    "Install the `openai` package and locate its path, as well as the path to the `attrs` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca106e2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /cloud/lib/lib/python3.8/site-packages (0.27.2)\n",
      "Requirement already satisfied: tqdm in /cloud/lib/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.20 in /cloud/lib/lib/python3.8/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: aiohttp in /cloud/lib/lib/python3.8/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cloud/lib/lib/python3.8/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cloud/lib/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cloud/lib/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cloud/lib/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cloud/lib/lib/python3.8/site-packages (from aiohttp->openai) (22.2.0)\n",
      "Name: openai\n",
      "Version: 0.27.2\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: None\n",
      "Location: /cloud/lib/lib/python3.8/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb25443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: attrs\r\n",
      "Version: 22.2.0\r\n",
      "Summary: Classes Without Boilerplate\r\n",
      "Home-page: https://www.attrs.org/\r\n",
      "Author: Hynek Schlawack\r\n",
      "Author-email: hs@ox.cx\r\n",
      "License: MIT\r\n",
      "Location: /cloud/lib/lib/python3.8/site-packages\r\n",
      "Requires: \r\n",
      "Required-by: aiohttp, jsonschema\r\n"
     ]
    }
   ],
   "source": [
    "!pip show attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac1e77",
   "metadata": {},
   "source": [
    "In addition to locating the paths for the `openai` and `attrs` packages, you may also want to view all the system paths that are included in the current Python script. This can be useful for troubleshooting issues related to missing modules or packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d6725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cloud/project', '/opt/python/3.8.10/lib/python38.zip', '/opt/python/3.8.10/lib/python3.8', '/opt/python/3.8.10/lib/python3.8/lib-dynload', '', '/cloud/lib/lib/python3.8/site-packages', '/opt/python/3.8.10/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fe113",
   "metadata": {},
   "source": [
    "If the paths to `openai` and `attrs` packages are not included in the list of system paths, add them to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6070493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/cloud/lib/lib/python3.8/site-packages\")\n",
    "sys.path.append(\"/usr/local/lib/python3.8/dist-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0500a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/cloud/project', '/opt/python/3.8.10/lib/python38.zip', '/opt/python/3.8.10/lib/python3.8', '/opt/python/3.8.10/lib/python3.8/lib-dynload', '', '/cloud/lib/lib/python3.8/site-packages', '/opt/python/3.8.10/lib/python3.8/site-packages', '/cloud/lib/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3f111",
   "metadata": {},
   "source": [
    "Provide your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e148ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"your_api_key_here\" with your actual API key\n",
    "api_key =\"your_api_key_here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf4498",
   "metadata": {},
   "source": [
    "Convert the csv data file into a jsonl file for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c50dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Open the CSV input file and JSONL output file\n",
    "with open('qna_chitchat_friendly.csv', 'r') as input_file, open('training_data.jsonl', 'w') as output_file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.DictReader(input_file)\n",
    "    # Iterate over the rows in the CSV file and convert each row to a JSON object\n",
    "    for row in csv_reader:\n",
    "        # Create a dictionary with the \"prompt\" and \"completion\" keys\n",
    "        # separate prompts and completions using the suggested common separator \"\\n\"\n",
    "        json_obj = {\n",
    "            \"prompt\": row[\"Question\"],\n",
    "            \"completion\": row[\"Answer\"]+\"\\n\"\n",
    "        }\n",
    "        # Write the JSON object to the output file as a single line in JSONL format\n",
    "        output_file.write(json.dumps(json_obj) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124628e",
   "metadata": {},
   "source": [
    "Upload the `training_data.jsonl` file to OpenAI and obtain the assigned file id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9a84d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Upload the file to OpenAI\n",
    "with open(\"training_data.jsonl\", \"rb\") as file:\n",
    "    upload_response = openai.File.create(\n",
    "        file=file,\n",
    "        purpose=\"fine-tune\"\n",
    "    )\n",
    "\n",
    "# Get the ID of the uploaded file\n",
    "file_id = upload_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0cb78330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-A5s6c6Kvk9M4yDH3qK8A4yAn'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0aa7c",
   "metadata": {},
   "source": [
    "Choose one from the four pre-trained base models, `ada`, `babbage`, `curie`, or `davinci`, to fine-tune using the uploaded training data file. The `ada` model is the smallest and has the least number of parrameters; the `davinci` model is the largest and most powerful one. If you don't specify a base model to train, the default model selection is `curie`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f3ce5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=\"file-A5s6c6Kvk9M4yDH3qK8A4yAn\", model=\"davinci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10638fa",
   "metadata": {},
   "source": [
    "To check the status of the fine-tuned model, look for a `pending` status, which indicates that all the code above has executed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d8c5627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pending'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response.status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8550c",
   "metadata": {},
   "source": [
    "Please allow 10 to 30 minutes for OpenAI to build the fine-tuned model, keeping in mind that the time required may vary depending on the size of the model being fine-tuned. For instance, `ada` takes the shortest time while `davinci` takes the longest.\n",
    "\n",
    "Then, log into your OpenAI account, navigate to the `Usage` page in the left-sidebar and locate `Daily usage breakdown` section, and choose the current date. Next, click on `Fine-tune training` and find the model ID as below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91c6f4",
   "metadata": {},
   "source": [
    "![Fine-tuned model id](https://filedn.com/lJpzjOtA91quQEpwdrgCvcy/Business%20Data%20Mining%20and%20Knowledge%20Discovery/chatGPT/fine-tuned%20model%20id.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca3fd1",
   "metadata": {},
   "source": [
    "Set the `model_id` and a new prompt to receive a response from the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e053e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID of the fine-tuned GPT-3 model\n",
    "model_id = \"davinci:ft-personal-2023-03-26-22-11-22\"\n",
    "\n",
    "# Set a new prompt for text generation\n",
    "prompt = \"what's your name?\"\n",
    "\n",
    "# Generate text using the fine-tuned GPT-3 model\n",
    "response = openai.Completion.create(\n",
    "    \n",
    "    engine=model_id, # A variable containing the ID of the fine-tuned GPT-3 model being used\n",
    "    prompt=prompt, \n",
    "    temperature=0.8, # Controls the randomness and creativity of the generated output. \n",
    "                     # Lower values will produce more conservative output, while higher \n",
    "                     # values will produce more creative output. The default value is 1.0, \n",
    "                     # and 0.8 is used in this example.\n",
    "    \n",
    "    max_tokens=10,   # The maximum number of tokens (words or sub-words) in the generated output. \n",
    "                     # If the model reaches this limit, it will stop generating new output. \n",
    "                     # The default value is 2048, and 10 is used in this example.\n",
    "    \n",
    "    n=1,             # The number of output texts to generate. The default value is 1, and 1 is used in this example.\n",
    "    \n",
    "    stop=None,       # Specifies a stopping sequence for the generated output. When the model \n",
    "                     # generates this sequence, it will stop generating new output. The default value is None,\n",
    "                     # which means the model will continue generating output until it reaches the max_tokens limit.\n",
    "    \n",
    "    timeout=30,      # The maximum time in seconds to wait for a response from the OpenAI API. If the API does not \n",
    "                     # respond within this time, an exception will be raised. The default value is 60 seconds, and \n",
    "                     # 30 is used in this example.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "892edb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, I don't have a name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc54e48",
   "metadata": {},
   "source": [
    "You may delete the fine-tuned model if you on longer use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c45dabc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=davinci:ft-personal-2023-03-26-22-11-22 at 0x7f90f7a4ae00> JSON: {\n",
       "  \"deleted\": true,\n",
       "  \"id\": \"davinci:ft-personal-2023-03-26-22-11-22\",\n",
       "  \"object\": \"model\"\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Model.delete(\"davinci:ft-personal-2023-03-26-22-11-22\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 - rstudio",
   "language": "python",
   "name": "rstudio-user-3.8.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
